I"∑0<p><a href="http://www.fabfile.org">Fabric</a> is a remote execution tool, written in Python, which ease parallel execution and orchestration of commands on different nodes.</p>

<p>Why does it matter with Puppet?</p>

<p>Because it‚Äôs a good candidate, and not a rare choice, to trigger Puppet runs (and more) from a central location.</p>

<p>In <a href="https://github.com/example42/psick">PSICK</a>, our Puppet control-repo [generator], we use it for several tasks tasks which are related to the whole Puppet code workflow, from development, to testing and deployment.</p>

<p>We can install Fabric, as common with Python software, using <strong>pip</strong>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install fabric
</code></pre></div></div>

<p>Once installed we have at disposal the <strong>fab</strong> executable, which reads a file called <code class="highlighter-rouge">fabfile.py</code> to get the list of available Fabric commands.</p>

<p>In PSICK we gathered different fab files for different purposes in a single <a href="https://github.com/example42/psick/tree/production/fabfile">directory</a> give them a look for an idea of their format. Being written in Python they can have a much more complex and flexible content.</p>

<p>To list the available commands in the local fabfile (or directory) we can type:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab -l
</code></pre></div></div>

<p>Fabric commands can be executed locally on remote nodes. On remote nodes it uses SSH for connection. There are various ways to define the list of remote nodes where to execute a given command, the simplest one is probably to specify them directly in the command line with the <code class="highlighter-rouge">-H</code> argument followed by a comma separated list of nodes or using the <code class="highlighter-rouge">:host</code> argument:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab &lt;task&gt;[:host=&lt;hostname&gt;][:option=value]
fab [-H &lt;hostname&gt;] &lt;task&gt;[:option=value]&gt;
</code></pre></div></div>

<p>Note that there are other ways to define and group the nodes to work with, for example by using Fabric <strong>roles</strong>, refer to the <a href="http://docs.fabfile.org/en/1.13/usage/execution.html#defining-host-lists">official documentation</a> for details.</p>

<p>Typically access to the remote node is done using SSH keys, using the local user for remote authentication, if keys are not used a password is prompted.</p>

<p>If local and remote users don‚Äôt match, or access to a remote node can‚Äôt be direct and requires a jump host, it‚Äôs definitively worth adding the relevant nodes in our <code class="highlighter-rouge">~/.ssh/config</code> file, where we define for our nodes, the user to access them, the SSH key to use, eventually a jump host and so on. Syntax for SSH client file is something like:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Host mon
    ProxyCommand ssh -A -x -W %h:%p bastion.aws.example.com 2&gt; /dev/null
    ForwardAgent yes
    User ec2-user
    Hostname 10.10.2.160
    IdentityFile ~/.ssh/aws.pem
</code></pre></div></div>

<p>In this way we can connect to this host, with all the correct configurations, with <code class="highlighter-rouge">ssh mon</code>, or, when using Fabric, <code class="highlighter-rouge">fab -H mon</code>.</p>

<h3 id="fabric-on-psick">Fabric on PSICK</h3>

<p>We mentioned PSICK and its integration with Puppet, the list of available commands is not short:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>al@mule psick [development] $ fab -l
Available commands:

    aws.apply                  [local] Run puppet apply locally using the specified role (default: aws)
    aws.setup                  [local] Install locally the aws cli environment
    aws.status                 [local] Show AWS resources on one or all regions
    docker.purge               [local] Clean up docker images and containers (CAUTION)
    docker.rocker_build_role   [local] WIP Rockerize a role on all or the specified image OS (data in hieradata/role/$puppetrole.yaml)
    docker.setup               [local] Install locally Docker (needs su privileges)
    docker.status              [local] Show Docker status info
    docker.test_role           [local] Test a role on the specified OS on a Docker image
    docker.tp_build_role       [local] Dockerize a role based on tp on all or the specified Docker (data in hieradata/role/$puppetrole.yaml)
    facter.set_external_facts  [remote] Set the given external facts in /etc/puppetlabs/facter/facts.d
    facter.set_trusted_facts   [remote] Set the given trusted facts in /etc/puppetlabs/puppet/csr_attributes.yaml
    git.checkout_master        [local] Run git checkout master on each on the installed modules
    git.install_hooks          [local] Install Puppet .git/hooks
    git.setup_new_repo         [local] Create a new repo from scratch, based on the current contents of this control-repo
    git.status                 [local] Run git status on this repo and the installed modules
    puppet.agent               [remote] Run puppet agent
    puppet.agent_noop          [remote] Run puppet agent in noop mode
    puppet.apply               [remote] Run puppet apply on the deployed control-repo (uses control-repo in the environments/production dir)
    puppet.apply_noop          [remote] Run puppet apply in noop mode (needs to have this control-repo deployed)
    puppet.check_syntax        [local] Check the syntax of all .pp .erb .yaml files in the contro-repo
    puppet.current_config      [remote] Show currently applied version of our Puppet code
    puppet.deploy_controlrepo  [remote] Deploy this control repo on a node (Puppet has to be already installed)
    puppet.install             [remote] Install Puppet 4 on a node (for Puppet official repos)
    puppet.lint                [local] Run puppet-lint on all site manifests. Eventually fix them
    puppet.module_generate     [local] Generate a Puppet module based on skeleton
    puppet.module_publish      [local] Publish on GitHub and the Forge the local version of a module
    puppet.remote_setup        [remote] Installs on a remote node the packages needed for a puppet apply run on the control-repo
    puppet.setup               [local] Setup the contro-repo, installs r10k and external modules
    puppet.sync_and_apply      [remote] Run puppet apply on a synced copy of the local git repo (syncs and uses control-repo)
    tp.clone_data              [local] Add a new app name data directory under modules/tinydata, based on the specified source
    tp.install                 [local] Install locally any tinydata knows app via tp
    tp.remote_test             [remote] WIP Run tp tests on remote node
    vagrant.destroy            [local] Destroy the specified vm
    vagrant.env_status         [local] Run vagrant status on all or the specified environments
    vagrant.halt               [local] Halt all or the specified Vagrant vm
    vagrant.node_test          [local] Run existing and testing Puppet code on a VM
    vagrant.provision          [local] Provision all or the specified vm
    vagrant.reload             [local] Reload all or the specified vm
    vagrant.resume             [local] Resume all or the specified vm
    vagrant.setup              [local] Install locally Vagrant and the needed plugins
    vagrant.status             [local] Show status of all or the specified vm
    vagrant.suspend            [local] Suspend all or the specified vm
    vagrant.up                 [local] Vagrant up the specified vm
</code></pre></div></div>

<p>Many of these commands are executed locally (and just wrap simple shell commands present in PSICK‚Äôs <code class="highlighter-rouge">bin/</code> directory), but there are some intended to be used on remote nodes.</p>

<p>For example, to install Puppet on one or more remote nodes we can run:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.install -H host1,host2
</code></pre></div></div>

<p>To run puppet agent in noop mode on all the known hosts (as defined in fabiles, or in the environment):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.agent_noop
</code></pre></div></div>

<p>To run puppet agent on a specific node:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.agent -H web01.example.test
</code></pre></div></div>

<p>To run in apply mode the local code on a remote node (code is rsynced and then compiled on the remote node, eventual eyaml keys and first copied and then removed):.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.sync_and_apply
</code></pre></div></div>

<h3 id="local-puppet-activities-with-psick">Local Puppet activities with PSICK</h3>

<p>Local commands are, generally, not ommon in Fabric, as the tools is supposed to be used for remote execution, still in PSICK there are several commands available to support us in our Puppet code workflow.</p>

<p>For example, to install useful git hooks for Puppet development. By default downloaded from (https://github.com/drwahl/puppet-git-hooks)[https://github.com/drwahl/puppet-git-hooks]:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab git.install_hooks
</code></pre></div></div>

<p>To generate a new module based on the format of PSICK‚Äôs <code class="highlighter-rouge">skeleton</code> directory.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.module_generate
</code></pre></div></div>

<p>To check the git status of the main control-repo and of each module in <code class="highlighter-rouge">modules</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab git.status
</code></pre></div></div>

<p>To check the syntax of all .pp .yaml .epp .erb files in our control-repo:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.check_syntax
</code></pre></div></div>

<p>To publish the local version of a module in modules/ dir to Forge and GitHub (puppet-blacksmith setup and access to remote git repo required):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab puppet.module_publish:&lt;module_name&gt;
</code></pre></div></div>

<p>To test a role (as defined in <code class="highlighter-rouge">hieradata/role/$role.yaml</code>) with Docker on different OS base images:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fab docker.test_role:&lt;role&gt;,&lt;image&gt;
fab docker.test_role:log,ubuntu-14.04
</code></pre></div></div>

<p>Available images are: ubuntu-12.04, ubuntu-14.04, ubuntu-14.06, centos-7, debian-7, debian-8, alpine-3.3.</p>

<p>These are just examples, give a look to the list of available commands for more, and use the <code class="highlighter-rouge">-d</code> argument to show a list of available  arguments:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>al@mule psick [development] $ fab -d docker.test_role
Displaying detailed information for task 'docker.test_role':

    [local] Test a role on the specified OS on a Docker image
    Arguments: puppetrole='docker_test_role', image='centos-7'
</code></pre></div></div>

<p>The fabfiles on PSICK are rather basic, but much more can be do, list of nodes can be automatically queried to AWS or PuppetDB, commands can be the result of more or less Python code, which may trigger remote backups, check for systems status, perform database operations, applications deployment and so on.</p>

<p>So, even if not strictly necessary (not even in PSICK), Fabric can be a good companion to Puppet and generally to the whole operations.</p>

<p>It‚Äôs usage inside a control-repo may give to it a whole new meaning, which goes further than a ‚Äúsimple‚Äù central repository for Puppet code and data, and may become the single place from where the whole infrastructure can be provisioned, configured, controlled, and managed.</p>

<p>The limit is our imagination.</p>

<p>Alessandro Franceschi</p>
:ET